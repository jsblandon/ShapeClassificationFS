{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mainFS_Demo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAYA77+VKyCUmToQtyQECd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nBXy_MEw_leX","colab_type":"text"},"source":["# **DEMO:  Feature Selection using GridSearchCV/RandomizedSearchCV into a Python Pipeline**"]},{"cell_type":"markdown","metadata":{"id":"kdoUr0tB_2ht","colab_type":"text"},"source":["Importing needed packages"]},{"cell_type":"code","metadata":{"id":"7e1ZKgYM_xOJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"164d4b25-d13a-43e3-9607-4aa817a6b737","executionInfo":{"status":"ok","timestamp":1587315603084,"user_tz":300,"elapsed":755,"user":{"displayName":"Juan Sebastian Blandon Luengas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjPkskViXCTt9OP-dhgS540cHhkSJbIN5de0hvuA=s64","userId":"16942134963990678590"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","import seaborn as sns\n","import math\n","import os"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"V_BHv-nJ_7cd","colab_type":"text"},"source":["ReliefF package installation"]},{"cell_type":"code","metadata":{"id":"ZgzJ59sy_9xT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"152c264e-0356-4fc7-e0d7-1e05d91d86eb","executionInfo":{"status":"ok","timestamp":1587315607868,"user_tz":300,"elapsed":3497,"user":{"displayName":"Juan Sebastian Blandon Luengas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjPkskViXCTt9OP-dhgS540cHhkSJbIN5de0hvuA=s64","userId":"16942134963990678590"}}},"source":["!pip install --user skrebate"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: skrebate in /root/.local/lib/python3.6/site-packages (0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skrebate) (1.18.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from skrebate) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from skrebate) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->skrebate) (0.14.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BwRVEt_GAAfN","colab_type":"text"},"source":["Specific functions importing"]},{"cell_type":"code","metadata":{"id":"CNwnUdCBADvC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"012ea7e0-dca1-4226-9a6f-88c29dec955f","executionInfo":{"status":"ok","timestamp":1587315612933,"user_tz":300,"elapsed":1112,"user":{"displayName":"Juan Sebastian Blandon Luengas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjPkskViXCTt9OP-dhgS540cHhkSJbIN5de0hvuA=s64","userId":"16942134963990678590"}}},"source":["from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score, cross_val_predict, RandomizedSearchCV\n","from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","from sklearn.pipeline import Pipeline\n","from sklearn.base import  BaseEstimator, TransformerMixin\n","from skrebate import ReliefF\n","from sklearn.metrics import roc_curve, auc\n","from scipy import interp\n","from itertools import cycle\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","from sklearn.linear_model import LogisticRegression, SGDClassifier, LassoCV\n","from sklearn.svm import LinearSVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.externals import joblib\n","from tqdm import tqdm\n","from numpy import array"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6W8yNhaGAHLU","colab_type":"text"},"source":["Avoiding unnecesary warning"]},{"cell_type":"code","metadata":{"id":"W211FdpZAKAv","colab_type":"code","colab":{}},"source":["warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3owgb6yALju","colab_type":"text"},"source":["Fixing a seed to set experimental reproducibility"]},{"cell_type":"code","metadata":{"id":"7y1iwUgnAU2D","colab_type":"code","colab":{}},"source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3KA1dFf0AWwN","colab_type":"text"},"source":["Since this notebook runs Google Colab, we suggest to mount your Drive account"]},{"cell_type":"code","metadata":{"id":"6geHJrLFBM3K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"580bc5c9-996b-494f-f3ef-1b9805646343","executionInfo":{"status":"ok","timestamp":1587315757973,"user_tz":300,"elapsed":141215,"user":{"displayName":"Juan Sebastian Blandon Luengas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjPkskViXCTt9OP-dhgS540cHhkSJbIN5de0hvuA=s64","userId":"16942134963990678590"}}},"source":["from google.colab import files, drive\n","\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lMReYTDDBP82","colab_type":"text"},"source":["Inline $\\texttt{matplotlib}$ plots"]},{"cell_type":"code","metadata":{"id":"fVP4xdiPBVoq","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHlO-4giBXVF","colab_type":"text"},"source":["Useful function to save figures and store results"]},{"cell_type":"code","metadata":{"id":"2JX0RWwiBbc6","colab_type":"code","colab":{}},"source":["# Function to store plots\n","def save_fig(path_img, fig_id, tight_layout = True, fig_extension = \"png\", resolution = 300):\n","    path = os.path.join(path_img, fig_id + \".\" + fig_extension)\n","    print(\"Guardando...\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8ID8m2RBdzB","colab_type":"code","colab":{}},"source":["# Function to plot ROC curve\n","def plot_roc_curve(fpr, tpr, label=None):\n","    plt.plot(fpr, tpr, linewidth=2, label=label)\n","    plt.plot([0, 1], [0, 1], 'k--') \n","    plt.axis([0, 1, 0, 1])\n","    plt.xlabel('False Positive Rate', fontsize=16)\n","    plt.ylabel('True Positive Rate', fontsize=16)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gucRXOTzBgP1","colab_type":"code","colab":{}},"source":["# Function to compute class-wise ROC curve and ROC area\n","def roc_multiclass(ytrue,yscore):\n","    fpr       = dict() # False positive rate\n","    tpr       = dict() # True positive rate\n","    roc_auc   = dict()\n","    n_classes = ytrue.shape[1]\n","    for i in range(n_classes):\n","        fpr[i], tpr[i], _ = roc_curve(ytrue[:, i], yscore[:, i])\n","        roc_auc[i]        = auc(fpr[i], tpr[i])\n","\n","    # Micro-average computation from ROC curve and ROC area\n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ytrue.ravel(), yscore.ravel())\n","    roc_auc[\"micro\"]              = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    return roc_auc, fpr, tpr, n_classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jpyl-i20B6k2","colab_type":"code","colab":{}},"source":["# Function to plot ROC curve and stores them\n","def roc_auc_mc(roc_auc,fpr,tpr,n_classes,title,path_img):   \n","    lw = 2\n","    # First, we add all false postive rates\n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","    \n","    # Then, it is interpolated each ROC curve over these points\n","    mean_tpr= np.zeros_like(all_fpr)\n","    for i in range(n_classes):\n","        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","\n","    # Finally, it is computed the AUC\n","    mean_tpr /= n_classes\n","\n","    fpr[\"macro\"]     = all_fpr\n","    tpr[\"macro\"]     = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","    # Each ROC curve is plotted\n","    plt.figure(figsize=(6,6))\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n","             label='micro-average ROC curve (area = {0:0.2f})'\n","                   ''.format(roc_auc[\"micro\"]),\n","             color='deeppink', linestyle=':', linewidth=4)\n","\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n","             label='macro-average ROC curve (area = {0:0.2f})'\n","                   ''.format(roc_auc[\"macro\"]),\n","             color='navy', linestyle=':', linewidth=4)\n","\n","    #colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n","    colors = sns.color_palette(None, n_classes)\n","    for i, color in zip(range(n_classes), colors):\n","        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n","                 label='AUC_class_{0} (area = {1:0.2f})'\n","                 ''.format(i, roc_auc[i]))\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"best\") \n","    save_fig(path_img,title)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E75w7SV3Cb2n","colab_type":"code","colab":{}},"source":["# Function to plot confusion matrices\n","def plot_confusion_matrix(y_true, y_pred, classes,normalize=False,title=None,cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix. Normalitzation is done\n","    setting normalize = True\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","            \n","    # Confusion matrix computation\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Classes are obtained from data labels\n","    classes = classes[unique_labels(y_true, y_pred)-1]\n","    if normalize:\n","        cm = 100*cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        \n","    fig, ax = plt.subplots()\n","    im      = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # All ticks are shown...\n","    ax.set(xticks = np.arange(cm.shape[1]),\n","           yticks = np.arange(cm.shape[0]),\n","           # ... and their respective labels \n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel = 'True label',\n","           xlabel = 'Predicted label')\n","    \n","    # Ticks labels and alignment rotation\n","    plt.setp(ax.get_xticklabels(), rotation = 45, ha = \"right\", rotation_mode = \"anchor\")\n","    \n","    plt.autoscale()\n","    return ax"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VZUOv8bDJJA","colab_type":"code","colab":{}},"source":["# This class allows to represent an input Data matrix as a similarity/dissimilarity\n","# matrix\n","class Dist_Rep(BaseEstimator, TransformerMixin):\n","    def __init__(self, metric = 'euclidean', n_jobs = None):\n","        self.metric = metric\n","        self.n_jobs = n_jobs\n","        \n","    def fit(self, X, *_):\n","        self.Xtrain = X\n","        return self\n","    \n","    def transform(self, X):\n","        return pairwise_distances(X, self.Xtrain)\n","    \n","    def fit_tranform(self,X,Y):\n","        self.fit(X)\n","        return pairwise_distances(Y,self.Xtrain)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xh799yAFDddv","colab_type":"text"},"source":["Setting the image directory"]},{"cell_type":"code","metadata":{"id":"YMyEbFNnDcyG","colab_type":"code","colab":{}},"source":["# KIMIA 99-SHAPE DATABASE\n","img_dir = './Machine Learning/ML Codes/MLPython/Databases/CorrectedDBs/Kimia99Shape_DB_Corrected'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZdrpT6UrDuD4","colab_type":"text"},"source":["# **Step 1: It is load an specific feature representation**"]},{"cell_type":"code","metadata":{"id":"l6oPP8x5D6nW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"95319ae3-591e-40cc-a6b3-d96f689f4daf","executionInfo":{"status":"ok","timestamp":1587315779810,"user_tz":300,"elapsed":7923,"user":{"displayName":"Juan Sebastian Blandon Luengas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjPkskViXCTt9OP-dhgS540cHhkSJbIN5de0hvuA=s64","userId":"16942134963990678590"}}},"source":["# Database directory\n","\n","# To load BoCF-based representation\n","data_dir = \"./Machine Learning/ML Codes/MLPython/Databases/PreprocessingBoCFKimia99ShapeDB(csv-version)\"\n","\n","# To load DTW-CCS-based representation\n","# data_dir = \"./Machine Learning/ML Codes/MLPython/Databases/Kimia99ShapeDB_DTW_CCSFeatRep(csv-version)\"\n","\n","# To load DTW-CS-based representation\n","# data_dir = \"./Machine Learning/ML Codes/MLPython/Databases/Kimia99ShapeDB_DTW_CSFeatRep(csv-version)\"\n","\n","# Set the representation flag: BoCF, DTW-CCS and DTW-CS, according to the data\n","# prviously loaded\n","typeR    = 'BoCF'\n","\n","X        = pd.read_csv(data_dir + '.csv')\n","y        = np.array(X.iloc[:,-1])\n","X.drop(columns=X.columns[-1],inplace=True)\n","X.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(99, 31500)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"HYhXgVlxEp9m","colab_type":"text"},"source":["# **Step 2: Variable declaration to store results and models**"]},{"cell_type":"code","metadata":{"id":"bQS9F9dfExpA","colab_type":"code","colab":{}},"source":["# Variable declaration\n","n_partitions = 10\n","test_per     = 0.5\n","n_classes    = len(np.unique(y))\n","f_step       = 1500\n","fold         = 0\n","train_idx    = []\n","test_idx     = []\n","alpha_L      = []\n","alpha_LogR   = []\n","alpha_lSVM   = []\n","sel_fts_L    = []\n","sel_fts_LogR = []\n","sel_fts_lSVM = []\n","thld_L       = []\n","thld_LogR    = []\n","thld_lSVM    = []\n","sel_fts_Lt   = []\n","sel_fts_LogRt= []\n","sel_fts_lSVMt= []\n","nfeats_L     = []\n","nfeats_LogR  = []\n","nfeats_lSVM  = []\n","accuracy_L   = np.zeros((n_partitions))\n","accuracy_LogR= np.zeros((n_partitions))\n","accuracy_lSVM= np.zeros((n_partitions))\n","cm_L         = np.zeros((n_partitions,n_classes,n_classes))\n","cm_LogR      = np.zeros((n_partitions,n_classes,n_classes))\n","cm_lSVM      = np.zeros((n_partitions,n_classes,n_classes))\n","cr_L         = []\n","cr_LogR      = []\n","cr_lSVM      = []\n","best_mod_L   = []\n","best_mod_LogR= []\n","best_mod_lSVM= []\n","best_pms_L   = []\n","best_pms_LogR= []\n","best_pms_lSVM= []\n","\n","if typeR == 'BoCF' or typeR == 'DTW-CCS':\n","  # For BoCF and DTW-CCS representations\n","  ftr_vec      = np.arange(0,int((X.shape[1]))+f_step,f_step).astype(int) \n","  ftr_vec      = ftr_vec[1:]\n","elif typeR == 'DTW-CS':\n","  # For DTW-CS representation\n","  ftr_vec      = np.arange(1,math.ceil((X.shape[0])*test_per),f_step).astype(int) \n","  ftr_vec[0]   = 1\n","\n","# Setting the data partition scheme to work like HoldOut validation\n","sss = StratifiedShuffleSplit(n_splits = n_partitions, test_size = test_per, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJaV8nsUMbar","colab_type":"code","colab":{}},"source":["\"\"\"Type of classification ensemble. \n","   'N' : To run classification\n","   'PR': To run classification including prototype representation \n","         (dissimilarity/similarity-based representation) \n","   'NE': To run classification and Non-Exhaustive feature selection including \n","         prototype representation\n","   'E' : To run classification and Exhaustive feature selection including \n","         prototype representation       \n","   'NE-NPR' : To run classification and Non-Exhaustive feature selection without \n","              including prototype representation \n","   'E-NPR'  : To run classification and Exhaustive feature selection without \n","              including prototype representation \n","\"\"\"\n","typeC        = 'E-NPR'\n","\n","# Model declaration\n","\n","# ------------------------------------------------------------------------------\n","# CLASSIFICATION\n","if typeC == 'N':\n","    # Steps to be include into Pipeline\n","    steps = [\n","            [('Preprocessing2',StandardScaler()),\n","             ('Classification',SGDClassifier())],      # Linear Classifier\n","            [('Preprocessing2',StandardScaler()),\n","             ('Classification',LogisticRegression())], # Logistic Regression\n","            [('Preprocessing2',StandardScaler()),\n","             ('Classification',LinearSVC())],          # SVM\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'Classification__C': [0.01,0.1,1,10]},\n","                 {'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","    \n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']\n","# ------------------------------------------------------------------------------\n","# CLASSIFICATION FROM DISSIMILARITY/SIMILARITY REPRESENTATION\n","if typeC == 'PR':\n","    # Steps to be include into the Pipeline\n","    steps = [\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('Classification',SGDClassifier())],      # Linear Classifier\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('Classification',LogisticRegression())], # Logistic Regression\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('Classification',LinearSVC())],          # SVM\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'Classification__C': [0.01,0.1,1,10]},\n","                 {'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","    \n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']\n","# ------------------------------------------------------------------------------\n","# FEATURE SELECTION: NON-EXHAUSTIVE - LASSO    \n","elif typeC == 'NE':\n","    # Steps to be include into the Pipeline\n","    steps = [\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 250),threshold=\"mean\")),\n","             ('Classification',SGDClassifier())],      # Linear Classifier\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 250),threshold=\"mean\")),\n","             ('Classification',LogisticRegression())], # Logistic Regression\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 250),threshold=\"mean\")),\n","             ('Classification',LinearSVC())],          # SVM\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__C': [0.01,0.1,1,10]},\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","\n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']\n","# ------------------------------------------------------------------------------\n","# FEATURE SELECTION: EXHAUSTIVE - PROTOTYPE REPRESENTATION - RELIEFF\n","elif typeC == 'E':\n","    # Feature weigths storage\n","    scores_rlff_L    = []\n","    scores_rlff_LogR = []\n","    scores_rlff_lSVM = []\n","\n","    # Steps to be include into the Pipeline\n","    steps = [\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',SGDClassifier())],      # Linear Classifier\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',LogisticRegression())], # Logistic Regression\n","            [('Preprocessing', StandardScaler()),\n","             ('Representation',Dist_Rep()),\n","             ('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',LinearSVC())],          # SVM\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__C': [0.01,0.1,1,10]},\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","\n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']\n","# ------------------------------------------------------------------------------\n","# FEATURE SELECTION: NON-EXHAUSTIVE - WITHOUR PROTOTYPE REPRESENTATION - LASSO    \n","elif typeC == 'NE-NPR':\n","    # Steps to be include into the pipeline\n","    steps = [\n","            [('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 200,tol=1e-4),threshold=\"mean\")),\n","             ('Classification',SGDClassifier())],      # Clasificador Lineal\n","            [('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 200,tol=1e-4),threshold=\"mean\")),\n","             ('Classification',LogisticRegression())], # Regresion Logistica\n","            [('Preprocessing2',StandardScaler()),\n","             ('FeatureSelectn',SelectFromModel(LassoCV(n_alphas = 20, max_iter = 200,tol=1e-4),threshold=\"mean\")),\n","             ('Classification',LinearSVC())],          # Maquina de Vectores de Soporte\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__C': [0.01,0.1,1,10]},\n","                 {'FeatureSelectn__threshold': [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1],\n","                  'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","\n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']    \n","# ------------------------------------------------------------------------------\n","# FEATURE SELECTION: EXHAUSTIVE - WITHOUT PROTOTYPE REPRESENTATION - RELIEFF\n","elif typeC == 'E-NPR':\n","    # Feature weigths storage\n","    scores_rlff_L    = []\n","    scores_rlff_LogR = []\n","    scores_rlff_lSVM = []\n","\n","    # Steps to be include into the Pipeline\n","    steps = [\n","            [('Preprocessing', StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',SGDClassifier())],      # Linear Classifier\n","            [('Preprocessing', StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',LogisticRegression())], # Logistic Regression\n","            [('Preprocessing', StandardScaler()),\n","             ('FeatureSelectnRel',ReliefF()),\n","             ('Classification',LinearSVC())],          # SVM\n","            ]\n","    \n","    # Parameter grid declaration\n","    parameters = [\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__penalty': ['l1', 'l2', 'elasticnet'] },\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__C': [0.01,0.1,1,10]},\n","                 {'FeatureSelectnRel__n_features_to_select': ftr_vec,\n","                  'FeatureSelectnRel__n_neighbors':[1],\n","                  'Classification__C': [0.1,1,10,100,1000]}\n","                 ]\n","\n","    # Model labels\n","    label_models = ['Linear','LogisticRegression','LinearSVC']\n","# ------------------------------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M7U-6JJ8K6Xc","colab_type":"text"},"source":["Here, we suggest to just uncomment the lines according to the classification ensemble that you want to run. However, feel free to modify the directory names as you prefer"]},{"cell_type":"code","metadata":{"id":"f_D9VZpkK6h7","colab_type":"code","colab":{}},"source":["# Directory to save results and plots\n","\n","# BoCF-based scheme, without applying Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_Results/Results_BoCF_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_Results'\n","\n","# BoCF-based scheme, applying Exhaustive Feature Selection\n","rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_E_Results/Results_BoCF_E_Py'\n","img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_E_Results'\n","\n","# BoCF-based scheme, applying Non-Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_NE_Results/Results_BoCF_NE_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_BoCF_NE_Results'\n","\n","\n","# Dissimilarity/similarity BoCF-based scheme, without applying Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_Results/Results_PR_BoCF_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_Results'\n","\n","# Dissimilarity/similarity BoCF-based scheme, applying Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_E_Results/Results_PR_BoCF_E_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_E_Results'\n","\n","# Dissimilarity/similarity BoCF-based scheme, applying Non-Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_NE_Results/Results_PR_BoCF_NE_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_PR_BoCF_NE_Results'\n","\n","\n","# DTW-CCS scheme, without applying Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CCS_Results/Results_DTW_CCS_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CCS_Results'\n","\n","# DTW-CCS scheme, applying Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/Kimia99ShapeDB_DTW_CCS_E_Results/Results_DTW_CCS_E_Py'\n","# img_path     = img_dir + '/FeatureSelection/Kimia99ShapeDB_DTW_CCS_E_Results'\n","\n","# DTW-CCS scheme, applying Non-Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CCS_NE_Results/Results_DTW_CCS_NE_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CCS_NE_Results'\n","\n","\n","# DTW-CS scheme, without applying Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_Results/Results_DTW_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_Results'\n","\n","# DTW-CS scheme, applying Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_E_Results/Results_DTW_CS_E_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_E_Results'\n","\n","# DTW-CS scheme, applying Non-Exhaustive Feature Selection\n","# rslt_dir     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_NE_Results/Results_DTW_CS_NE_Py'\n","# img_path     = img_dir + '/FeatureSelection/DemoTest/Kimia99ShapeDB_DTW_CS_NE_Results'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbsUUmT5Q1sn","colab_type":"text"},"source":["# **Step 3: Feature Selection loop**"]},{"cell_type":"code","metadata":{"id":"JUX8d34GQuxa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"88ad4ac4-9538-439a-d03f-8aa1a55569e8"},"source":["# Traininig/Testing loop\n","\n","for train_index, test_index in tqdm(sss.split(X,y)):\n","    # Training/testing index storage\n","    train_idx += [train_index]\n","    test_idx  += [test_index]\n","    \n","    # Number of partitions flag\n","    fold = fold + 1\n","    print(\"Iteration = \", str(fold) +'/'+ str(n_partitions))\n","    \n","    # Iteration file name \n","    filename = img_path + \"/Fold\" + str(fold)\n","    \n","    # Train/Test \n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # ---------------------------------------------------------------------------------------------------------------------------\n","    # Training\n","    \n","    # Linear\n","    print('Linear Model')\n","    # Using GridSearchCV \n","    # hs_Lineal = GridSearchCV(Pipeline(steps[0]), parameters[0], n_jobs = 6, cv = 5, scoring = 'balanced_accuracy', verbose = 50)\n","    # Using RandomizedSearchCV\n","    hs_Lineal = RandomizedSearchCV(Pipeline(steps[0]), param_distributions=parameters[0],n_iter=10, cv=5, iid=False, n_jobs=-1)\n","    hs_Lineal.fit(X_train,y_train)\n","    if typeC == 'NE':\n","      # Features selected by LASSO\n","      alpha_L   += [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_L += [train_index[hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].get_support()]]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_L    += [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_Lt+= [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_L[-1]]\n","      nfeats_L  += [np.sum(sel_fts_Lt)]\n","    elif typeC == 'NE-NPR':\n","      # Features selected by LASSO\n","      alpha_L   += [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_L += [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].get_support()]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_L    += [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_Lt+= [hs_Lineal.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_L[-1]]\n","      nfeats_L  += [np.sum(sel_fts_Lt)]\n","    elif typeC == 'E' or typeC == 'E-NPR':\n","      # Features selected by ReliefF method\n","      nfeats_L     += [hs_Lineal.best_estimator_.named_steps['FeatureSelectnRel'].n_features_to_select]\n","      sel_fts_L    += [hs_Lineal.best_estimator_.named_steps['FeatureSelectnRel'].top_features_]\n","      scores_rlff_L+= [hs_Lineal.best_estimator_.named_steps['FeatureSelectnRel'].feature_importances_]\n","\n","\n","    # Logistic Regression\n","    print('Logistic Regression Model')\n","    # Usaing GridSearchCV \n","    # hs_LogR = GridSearchCV(Pipeline(steps[1]), parameters[1], n_jobs = 6, cv = 5, scoring = 'balanced_accuracy', verbose = 50)\n","    # Using RandomizedSearchCV\n","    hs_LogR = RandomizedSearchCV(Pipeline(steps[1]), param_distributions=parameters[1],n_iter=10, cv=5, iid=False,n_jobs=-1)\n","    hs_LogR.fit(X_train,y_train)\n","    if typeC == 'NE':\n","      # Features selected by LASSO\n","      alpha_LogR   += [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_LogR += [train_index[hs_LogR.best_estimator_.named_steps['FeatureSelectn'].get_support()]]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_LogR    += [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_LogRt+= [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_LogR[-1]]\n","      nfeats_LogR  += [np.sum(sel_fts_LogRt)]\n","    elif typeC =='NE-NPR':\n","      # Features selected by LASSO\n","      alpha_LogR   += [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_LogR += [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].get_support()]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_LogR    += [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_LogRt+= [hs_LogR.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_LogR[-1]]\n","      nfeats_LogR  += [np.sum(sel_fts_LogRt)]\n","    elif typeC == 'E' or typeC == 'E-NPR':\n","      # Features selected by ReliefF method\n","      nfeats_LogR     += [hs_LogR.best_estimator_.named_steps['FeatureSelectnRel'].n_features_to_select]\n","      sel_fts_LogR    += [hs_LogR.best_estimator_.named_steps['FeatureSelectnRel'].top_features_]\n","      scores_rlff_LogR+= [hs_LogR.best_estimator_.named_steps['FeatureSelectnRel'].feature_importances_]\n","    \n","\n","    # Linear SVM\n","    print('Linear SVM Model')\n","    # Using GridSearchCV \n","    #hs_lSVM = GridSearchCV(Pipeline(steps[2]), parameters[2], n_jobs = 6, cv = 5, scoring = 'balanced_accuracy', verbose = 50)\n","    # Using RandomizedSearchCV\n","    hs_lSVM = RandomizedSearchCV(Pipeline(steps[2]), param_distributions=parameters[2],n_iter=10, cv=5, iid=False, n_jobs=-1)  \n","    hs_lSVM.fit(X_train,y_train)\n","    if typeC == 'NE':\n","      # Features selected by LASSO\n","      alpha_lSVM   += [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_lSVM += [train_index[hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].get_support()]]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_lSVM    += [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_lSVMt+= [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_lSVM[-1]]\n","      nfeats_lSVM  += [np.sum(sel_fts_lSVMt)]\n","    elif typeC == 'NE-NPR':\n","      # Features selected by LASSO\n","      alpha_lSVM   += [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].estimator_.alpha_]\n","      sel_fts_lSVM += [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].get_support()]\n","      # Features selected according to threshold value from SelectFromModel()\n","      thld_lSVM    += [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].threshold_]\n","      sel_fts_lSVMt+= [hs_lSVM.best_estimator_.named_steps['FeatureSelectn'].estimator_.coef_>thld_lSVM[-1]]\n","      nfeats_lSVM  += [np.sum(sel_fts_lSVMt)]\n","    elif typeC == 'E' or typeC == 'E-NPR':\n","      # Features selected by ReliefF method\n","      nfeats_lSVM     += [hs_lSVM.best_estimator_.named_steps['FeatureSelectnRel'].n_features_to_select]\n","      sel_fts_lSVM    += [hs_lSVM.best_estimator_.named_steps['FeatureSelectnRel'].top_features_]\n","      scores_rlff_lSVM+= [hs_lSVM.best_estimator_.named_steps['FeatureSelectnRel'].feature_importances_]\n","\n","    # ---------------------------------------------------------------------------------------------------------------------------\n","    # Validation\n","    \n","    # Linear\n","    y_pred_L           = hs_Lineal.best_estimator_.predict(X_test)\n","    accuracy_L[fold-1] = accuracy_score(y_test,y_pred_L)\n","    cm_temp            = confusion_matrix(y_test,y_pred_L)\n","    cm_L[fold-1,:,:]   = 100*cm_temp.astype('float') / cm_temp.sum(axis=1)[:, np.newaxis]\n","    plot_confusion_matrix(y_test, y_pred_L, classes=np.unique(y),normalize=True,title='ACC = %.1f %% Fold %d' % (100*accuracy_L[fold-1],fold) + '_'+ label_models[0])\n","    plt.autoscale()\n","    save_fig(img_path,label_models[0]+'_Fold'+str(fold))                      \n","    plt.show()\n","    cr_L += [classification_report(y_test,y_pred_L)]\n","    print(cr_L[-1])\n","    # Best model storage\n","    # best_mod_L += [hs_Lineal.best_estimator_, accuracy_L,cm_L,cr_L, sel_fts_L]\n","    #best_mod_L += [hs_Lineal.best_estimator_]\n","    if typeC == 'E' or typeC == 'E-NPR':\n","      best_pms_L += [hs_Lineal.best_params_,nfeats_L,sel_fts_L,scores_rlff_L,accuracy_L,cm_L,cr_L]\n","    elif typeC == 'NE' or typeC == 'NE-NPR':\n","      best_pms_L += [hs_Lineal.best_params_,alpha_L,sel_fts_L,thld_L,sel_fts_Lt,nfeats_L,accuracy_L,cm_L,cr_L]\n","    elif typeC == 'N' or typeC == 'PR':\n","      best_pms_L += [hs_Lineal.best_params_,accuracy_L,cm_L,cr_L]\n","\n","    \n","    # Logistic Regression\n","    y_pred_LogR          = hs_LogR.best_estimator_.predict(X_test)\n","    accuracy_LogR[fold-1]= accuracy_score(y_test,y_pred_LogR)\n","    cm_temp              = confusion_matrix(y_test,y_pred_LogR)\n","    cm_LogR[fold-1,:,:]  = 100*cm_temp.astype('float') / cm_temp.sum(axis=1)[:, np.newaxis]\n","    plot_confusion_matrix(y_test, y_pred_LogR, classes=np.unique(y),normalize=True,title='ACC = %.1f %% Fold %d' % (100*accuracy_LogR[fold-1],fold) + '_'+ label_models[1])\n","    plt.autoscale()\n","    save_fig(img_path,label_models[1]+'_Fold'+str(fold))                      \n","    plt.show()\n","    cr_LogR += [classification_report(y_test,y_pred_LogR)]\n","    print(cr_LogR[-1])\n","    # Best model storage\n","    # best_mod_LogR += [hs_LogR.best_estimator_, accuracy_LogR,cm_LogR,cr_LogR, sel_fts_LogR]\n","    # best_mod_LogR += [hs_LogR.best_estimator_]\n","    if typeC == 'E' or typeC == 'E-NPR':\n","      best_pms_LogR += [hs_LogR.best_params_,nfeats_LogR,sel_fts_LogR,scores_rlff_LogR,accuracy_LogR,cm_LogR,cr_LogR]\n","    elif typeC == 'NE' or typeC == 'NE-NPR':\n","      best_pms_LogR += [hs_LogR.best_params_,alpha_LogR,sel_fts_LogR,thld_LogR,sel_fts_LogRt,nfeats_LogR,accuracy_LogR,cm_LogR,cr_LogR]\n","    elif typeC == 'N' or typeC == 'PR':\n","      best_pms_LogR += [hs_LogR.best_params_,accuracy_LogR,cm_LogR,cr_LogR]\n","    \n","\n","    # Linear SVM\n","    y_pred_lSVM          = hs_lSVM.best_estimator_.predict(X_test)\n","    accuracy_lSVM[fold-1]= accuracy_score(y_test,y_pred_lSVM)\n","    cm_temp              = confusion_matrix(y_test,y_pred_lSVM)\n","    cm_LogR[fold-1,:,:]  = 100*cm_temp.astype('float') / cm_temp.sum(axis=1)[:, np.newaxis]\n","    plot_confusion_matrix(y_test, y_pred_lSVM, classes=np.unique(y),normalize=True,title='ACC = %.1f %% Fold %d' % (100*accuracy_lSVM[fold-1],fold) + '_'+ label_models[2])\n","    plt.autoscale()\n","    save_fig(img_path,label_models[2]+'_Fold'+str(fold))                      \n","    plt.show()\n","    cr_lSVM += [classification_report(y_test,y_pred_lSVM)]\n","    print(cr_lSVM[-1])\n","    # Best model storage\n","    # best_mod_lSVM += [hs_lSVM.best_estimator_, accuracy_lSVM,cm_lSVM,cr_lSVM, sel_fts_lSVM]\n","    # best_mod_lSVM += [hs_lSVM.best_estimator_]\n","    if typeC == 'E' or typeC == 'E-NPR':\n","      best_pms_lSVM += [hs_lSVM.best_params_,nfeats_lSVM,sel_fts_lSVM,scores_rlff_lSVM,accuracy_lSVM,cm_lSVM,cr_lSVM]\n","    elif typeC == 'NE' or typeC == 'NE-NPR':\n","      best_pms_lSVM += [hs_lSVM.best_params_,alpha_lSVM,sel_fts_lSVM,thld_L,sel_fts_lSVMt,nfeats_lSVM,accuracy_lSVM,cm_L,cr_lSVM]\n","    elif typeC == 'N' or typeC == 'PR':\n","      best_pms_lSVM += [hs_lSVM.best_params_,accuracy_lSVM,cm_lSVM,cr_lSVM]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iteration =  1/10\n","Linear Model\n","Logistic Regression Model\n","Linear SVM Model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WYQhm_R1TKsk","colab_type":"text"},"source":["Once the feature selection loop has run, it is stored general results"]},{"cell_type":"code","metadata":{"id":"2jwG6ln8TSTf","colab_type":"code","colab":{}},"source":["if typeC == 'N' or typeC == 'PR':\n","  # Results dictionary creation\n","  L_dict = {'accuracy_L': accuracy_L,\n","            'cm_L': cm_L,\n","            'cr_L': cr_L}\n","\n","  LogR_dict = {'accuracy_LogR': accuracy_LogR,\n","              'cm_LogR': cm_LogR,\n","              'cr_LogR': cr_LogR}\n","\n","  lSVM_dict = {'accuracy_lSVM': accuracy_lSVM,\n","              'cm_lSVM': cm_lSVM,\n","              'cr_lSVM': cr_lSVM}\n","\n","elif typeC == 'NE' or typeC == 'NE-NPR':\n","  # Results dictionary creation\n","  L_dict = {'accuracy_L': accuracy_L,\n","            'cm_L': cm_L,\n","            'cr_L': cr_L,\n","            'sel_fts_L':sel_fts_L,\n","            'sel_fts_Lt':sel_fts_Lt,\n","            'alpha_L': alpha_L,\n","            'thld_L': thld_L,\n","            'nfeats_L': nfeats_L}\n","\n","  LogR_dict = {'accuracy_LogR': accuracy_LogR,\n","              'cm_LogR': cm_LogR,\n","              'cr_LogR': cr_LogR,\n","              'sel_fts_LogR':sel_fts_LogR,\n","              'sel_fts_LogRt':sel_fts_LogRt,\n","              'alpha_LogR': alpha_LogR,\n","              'thld_LogR': thld_LogR,\n","              'nfeats_LogR': nfeats_LogR}\n","\n","  lSVM_dict = {'accuracy_lSVM': accuracy_lSVM,\n","              'cm_lSVM': cm_lSVM,\n","              'cr_lSVM': cr_lSVM,\n","              'sel_fts_lSVMR':sel_fts_lSVM,\n","              'sel_fts_lSVMt':sel_fts_lSVMt,\n","              'alpha_lSVM': alpha_lSVM,\n","              'thld_lSVM': thld_lSVM,\n","              'nfeats_lSVM': nfeats_lSVM}\n","\n","elif typeC == 'E' or typeC == 'E-NPR':\n","  # Results dictionary creation\n","  L_dict = {'accuracy_L': accuracy_L,\n","            'cm_L': cm_L,\n","            'cr_L': cr_L,\n","            'sel_fts_L':sel_fts_L,\n","            'scores_rlff_L':scores_rlff_L,\n","            'nfeats_L': nfeats_L}\n","\n","  LogR_dict = {'accuracy_LogR': accuracy_LogR,\n","              'cm_LogR': cm_LogR,\n","              'cr_LogR': cr_LogR,\n","              'sel_fts_LogR':sel_fts_LogR,\n","              'scores_rlff_LogR':scores_rlff_LogR,\n","              'nfeats_LogR': nfeats_LogR}\n","\n","  lSVM_dict = {'accuracy_lSVM': accuracy_lSVM,\n","              'cm_lSVM': cm_lSVM,\n","              'cr_lSVM': cr_lSVM,\n","              'sel_fts_lSVM':sel_fts_lSVM,\n","              'scores_rlff_lSVM':scores_rlff_lSVM,\n","              'nfeats_lSVM': nfeats_lSVM}\n","\n","\n","Results = [L_dict, LogR_dict, lSVM_dict]\n","\n","joblib.dump(Results, rslt_dir + \".pkl\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7u2PzctTmpL","colab_type":"code","colab":{}},"source":["print('Linear Classifier')\n","print(np.mean(np.array(Results[0]['accuracy_L']))*100)\n","print(np.std(np.array(Results[0]['accuracy_L']))*100)\n","\n","print('Logistic Regression Classifier')\n","print(np.mean(np.array(Results[1]['accuracy_LogR']))*100)\n","print(np.std(np.array(Results[1]['accuracy_LogR']))*100)\n","\n","print('Linear SVM Classifier')\n","print(np.mean(np.array(Results[2]['accuracy_lSVM']))*100)\n","print(np.std(np.array(Results[2]['accuracy_lSVM']))*100)"],"execution_count":0,"outputs":[]}]}